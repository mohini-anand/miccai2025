{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw_LbWswORoy",
        "outputId": "6042a2aa-4687-4220-f29b-47fe5623cf13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "Found existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.9.0-cp310-cp310-manylinux1_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.9.0-cp310-cp310-manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchtext, torchdata, torchaudio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 torchaudio-2.5.1 torchdata-0.9.0 torchtext-0.18.0 torchvision-0.20.1 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9GPmuSei-58"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.amp import GradScaler, autocast\n",
        "import math\n",
        "from torch.utils.data import random_split\n",
        "from google.colab import drive, files\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRngNZTVVGx7",
        "outputId": "d6cd4a07-134c-422a-dead-2ddd95aec698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnp9QP7NUkoc"
      },
      "outputs": [],
      "source": [
        "pkl_file_path = \"/content/drive/MyDrive/Research: Computational Cardiovascular Models (1)/Computational Cardiac Models: Point RNN/Fall 2024: ML Models/Data Preparation/processed_fibers_longer_fibers.pkl\"\n",
        "\n",
        "with open(pkl_file_path, \"rb\") as f:\n",
        "    fibers = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xbBYhb1pfab",
        "outputId": "1f9e9ed8-0230-4465-a41e-cc2909e800f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(322933, 80734)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_fibers, test_fibers = train_test_split(fibers, test_size=0.2, random_state=42)\n",
        "len(train_fibers), len(test_fibers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4fOAUNZjFtF"
      },
      "source": [
        "# Data Preparation: Creating the Dataset class\n",
        "Since the fibers are all variable length, I will use packing to ensure that the model does not focus on padded values during forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od69MRKlndro",
        "outputId": "e828388e-2318-4195-e3d5-a8b4237fb837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(290640, 32293, 80734)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class FiberDataset(Dataset):\n",
        "    def __init__(self, fibers, predict_steps=25):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            fibers (list of tensors): List of fibers, where each fiber is a tensor of shape (num_points, num_features).\n",
        "            predict_steps (int): Number of future steps to predict.\n",
        "        \"\"\"\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "        self.lengths = []\n",
        "        self.predict_steps = predict_steps\n",
        "\n",
        "        for fiber in fibers:\n",
        "            seq_len = len(fiber)\n",
        "            if seq_len > predict_steps:\n",
        "                self.inputs.append(fiber[: -(predict_steps)]) # all points except the last `predict_steps`\n",
        "                self.targets.append( torch.stack([fiber[i : i + predict_steps] for i in range(seq_len - predict_steps)]))\n",
        "                self.lengths.append(seq_len - predict_steps)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx], self.lengths[idx]\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Collate function to pad sequences and return lengths.\n",
        "\n",
        "    Args:\n",
        "        batch: List of tuples (inputs, targets, lengths).\n",
        "            inputs: Tensor of shape (seq_len, input_size).\n",
        "            targets: Tensor of shape (seq_len, predict_steps, input_size).\n",
        "            lengths: Sequence lengths.\n",
        "\n",
        "    Returns:\n",
        "        Padded inputs: Tensor of shape (batch_size, max_seq_len, input_size).\n",
        "        Padded targets: Tensor of shape (batch_size, max_seq_len, predict_steps, input_size).\n",
        "        Lengths tensor: Tensor of shape (batch_size,).\n",
        "    \"\"\"\n",
        "    inputs, targets, lengths = zip(*batch)\n",
        "\n",
        "    # Pad inputs to the same length\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True)  # Shape: (batch_size, max_seq_len, input_size)\n",
        "\n",
        "    # Pad targets to the same length\n",
        "    max_seq_len = max([t.size(0) for t in targets])  # Find the max sequence length in the batch\n",
        "    predict_steps = targets[0].size(1)  # Number of prediction steps (25 in your case)\n",
        "    input_size = targets[0].size(2)  # Number of features per point (5 in your case)\n",
        "\n",
        "    targets_padded = torch.zeros(len(targets), max_seq_len, predict_steps, input_size)\n",
        "    for i, target in enumerate(targets):\n",
        "        seq_len = target.size(0)\n",
        "        targets_padded[i, :seq_len, :, :] = target  # Copy the target data into the padded tensor\n",
        "\n",
        "    # Convert lengths to a tensor\n",
        "    lengths_tensor = torch.tensor(lengths, dtype=torch.long)\n",
        "\n",
        "    return inputs_padded, targets_padded, lengths_tensor\n",
        "\n",
        "train_dataset = FiberDataset(train_fibers, predict_steps=25)\n",
        "test_dataset = FiberDataset(test_fibers, predict_steps=25)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_subset, val_subset = random_split(train_dataset, [0.9, 0.1])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=256, shuffle=True, num_workers=12, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=256, shuffle=False, num_workers=12, collate_fn=collate_fn, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=12, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "len(train_subset), len(val_subset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh8qldfynn9-",
        "outputId": "9c855a7e-5ae0-4bd4-ac4b-0da30b5288c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying Train Loader...\n",
            "Batch 1:\n",
            "  Inputs Shape: torch.Size([256, 513, 5])\n",
            "  Targets Shape: torch.Size([256, 513, 25, 5])\n",
            "  Lengths Shape: torch.Size([256])\n",
            "  Lengths: tensor([381, 117,  75,  12, 266, 123,  46, 179, 253, 288,  38, 351, 103, 227,\n",
            "        144,  50, 348,  49, 187,  40,  96, 314, 138,  76, 233,  98, 220,   6,\n",
            "        221, 243, 325, 331, 248, 335, 245,  67, 329, 196,  89, 260, 253, 347,\n",
            "        105, 281, 104,  29,  34, 219, 144,  81,  57,  83,  82, 219,  50, 149,\n",
            "        220, 191, 219, 257,  41,  39,  46, 197, 216, 197, 307, 117, 144, 247,\n",
            "        243, 155,  49, 252, 254, 100,  78, 230, 219,  80,  38,  74,  89, 104,\n",
            "        291,  43, 248,  60,  42,  57, 256,  47, 293, 247, 291, 456, 334, 192,\n",
            "        225, 245, 330,  45, 277, 132,  35, 217, 260,  53, 206, 476,  46,  37,\n",
            "         75, 182,  70,  59, 201, 243, 411, 346, 174, 193,  37, 141, 125, 100,\n",
            "        206,  51,  35, 256, 269, 113, 306, 255,  30, 141,  99,  34,  49, 177,\n",
            "        126, 311,  89, 229, 203,  49, 116, 222, 260,  51, 122,  10, 320, 208,\n",
            "        194, 128,  36,  76, 123, 206, 245, 266, 168, 152, 327, 338, 224,  10,\n",
            "         42,  60,  56,  77, 243, 141, 249, 276, 513,  84, 122, 260,  44, 131,\n",
            "        193, 190, 133, 237, 301,  50,  58, 172,  52, 226, 124, 225,  47,  21,\n",
            "         61,  28,  59, 186, 419,  47,  48,  41,  50, 149,  56, 156, 271,  41,\n",
            "         77, 272, 359, 227,  40, 249, 108,  28,  44, 167, 113,  78, 392, 392,\n",
            "        107, 164, 261,  49, 253, 202,  33,  53,  41, 259, 129, 108,  86, 245,\n",
            "         68,  47, 417, 159,  29, 304,  48, 411, 489, 183, 241,  83, 297, 162,\n",
            "        121, 134,  63, 326])\n",
            "  Inputs - Min: -88.81120300292969, Max: 89.86427307128906, NaNs: 0\n",
            "  Targets - Min: -88.81120300292969, Max: 89.86427307128906, NaNs: 0\n",
            "\n",
            "Verifying Validation Loader...\n",
            "Batch 1:\n",
            "  Inputs Shape: torch.Size([256, 503, 5])\n",
            "  Targets Shape: torch.Size([256, 503, 25, 5])\n",
            "  Lengths Shape: torch.Size([256])\n",
            "  Lengths: tensor([ 52, 133, 148,  33, 129, 286, 130, 280, 176, 162,  35, 314,  92, 147,\n",
            "        128,  21,  98, 244,  39, 161,  63, 286, 269,  78,  27, 169, 113,  76,\n",
            "        363, 126,  94, 188, 263, 192, 231,  71, 194, 211, 115,  48,  93,  33,\n",
            "        255, 477, 128, 246,  91,  47,  83,  45, 163, 230,  38,  99, 168, 112,\n",
            "        261, 134, 408, 296, 335,  67,  92,  86, 127, 122, 249,  53,  43, 465,\n",
            "        395, 503,  55, 262,  40,  78, 117,  87, 203, 243,  62,  81, 255,  59,\n",
            "        325,   8,  70,  66, 280, 285, 129,  75, 282, 126, 130,  39,  37, 212,\n",
            "         99,  91, 228, 156,  87,  64, 299, 116,  42, 186, 119, 121, 292, 208,\n",
            "         46, 359,   9,  96,  53, 114,  65, 111, 388,  13, 145, 286,  31,  56,\n",
            "        135, 308,  56, 296,  49,  58, 244, 273, 239, 335, 248, 305, 173,  66,\n",
            "        103,  63, 215,  82,  87,  95,  38, 105,   3,  94,  39,  67,  83, 156,\n",
            "         70, 376, 125, 125, 353, 484, 115, 190, 168,  19, 208,  59, 226, 241,\n",
            "        250, 245,  55,  29, 105, 230, 211,  48, 246, 232, 141,  99, 331,  75,\n",
            "          5,  63,  63, 152, 318, 267, 298,  94,  44, 222,  52,  55, 257, 276,\n",
            "         83, 310, 393, 285,  73,  97, 230, 421,  62,  72, 284, 183,  55, 322,\n",
            "         76,  52,  58,  87, 287, 244,  36,  81,  91,  45,  41,  14, 268,  45,\n",
            "        243, 281, 207, 165,  49,  49, 113, 144, 286, 137, 205, 212,  40, 221,\n",
            "         55,  46,  54,  99, 231,  44, 296,  76, 176, 261, 266, 161, 174,  67,\n",
            "          9, 351,  39, 216])\n",
            "  Inputs - Min: -87.3917465209961, Max: 89.07054138183594, NaNs: 0\n",
            "  Targets - Min: -87.3917465209961, Max: 89.07054138183594, NaNs: 0\n",
            "\n",
            "Verifying Test Loader...\n",
            "Batch 1:\n",
            "  Inputs Shape: torch.Size([256, 533, 5])\n",
            "  Targets Shape: torch.Size([256, 533, 25, 5])\n",
            "  Lengths Shape: torch.Size([256])\n",
            "  Lengths: tensor([ 94, 232, 234,  60, 429, 103, 121, 332,  59, 132,  79,  32,  20,  43,\n",
            "        299,  94,  77, 152, 241, 245, 115, 420, 295, 364,  75, 218,   7,  37,\n",
            "        164,  54,  74, 284,  82,  72, 150,  48, 265,  86, 453, 174,  54, 358,\n",
            "        239, 295,  90,  85,  37, 415, 190, 348, 452,  93, 253, 226,  74, 101,\n",
            "        194,  22, 243, 139,  39,  58, 234,  52, 144,  35, 274,  40, 330, 240,\n",
            "        389, 121, 225,  88, 136, 180, 250, 166, 238, 413, 256,  14, 286, 164,\n",
            "         49, 143, 283, 208,  37, 112, 211, 139,  30,  61, 269,  50, 118,  47,\n",
            "        266, 188, 116, 214,  67, 301,  72,   6, 327, 327, 242, 107,  89,  52,\n",
            "        135, 212, 466, 210, 216, 202,  57,  48, 102, 167, 245, 163, 377,  39,\n",
            "        260, 203, 252,  45, 315, 178, 175,  74, 236,  96,  46, 237,  52,  53,\n",
            "         51,  87, 214, 166,  32,   6, 314, 271, 166, 191,  38, 239,  90,  80,\n",
            "        263,  43,  37, 241, 478,  97,  40,  14, 260, 188, 206, 178, 219, 175,\n",
            "        147,  74, 240, 213, 103, 217, 300,  90, 326, 296, 129,  77, 101, 161,\n",
            "         81, 173,  56, 298, 236,  58,  65,  30, 222,  36, 161, 101, 218, 241,\n",
            "         61,  17, 288,  62,  70,  66, 184, 273,  86,  49, 114, 224,  59, 271,\n",
            "        101, 204, 282,  60, 294, 388,  52, 247,  53, 110,  53, 120, 319, 276,\n",
            "         66,  59, 118, 120,  71,   4, 250, 210, 460, 125,  82, 181, 167, 271,\n",
            "        271, 113, 533,  76, 117,  98, 265, 303,  88, 458, 264,  47, 104, 270,\n",
            "        237,  36, 305,  31])\n",
            "  Inputs - Min: -88.68921661376953, Max: 89.37841796875, NaNs: 0\n",
            "  Targets - Min: -88.68921661376953, Max: 89.37841796875, NaNs: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Verification for DataLoader and Dataset\n",
        "def verify_dataloader(dataloader):\n",
        "    \"\"\"\n",
        "    Function to verify the structure of the dataloader's output.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): Dataloader to verify.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints the shapes and statistics of the batches.\n",
        "    \"\"\"\n",
        "    for batch_idx, (inputs, targets, lengths) in enumerate(dataloader):\n",
        "        print(f\"Batch {batch_idx+1}:\")\n",
        "        print(f\"  Inputs Shape: {inputs.shape}\")  # Expected: (batch_size, max_seq_len, input_size)\n",
        "        print(f\"  Targets Shape: {targets.shape}\")  # Expected: (batch_size, max_seq_len, predict_steps, input_size)\n",
        "        print(f\"  Lengths Shape: {lengths.shape}\")  # Expected: (batch_size,)\n",
        "        print(f\"  Lengths: {lengths}\")  # Check actual sequence lengths\n",
        "        print(f\"  Inputs - Min: {inputs.min()}, Max: {inputs.max()}, NaNs: {torch.isnan(inputs).sum()}\")\n",
        "        print(f\"  Targets - Min: {targets.min()}, Max: {targets.max()}, NaNs: {torch.isnan(targets).sum()}\")\n",
        "        print(\"\")\n",
        "\n",
        "        # Break after the first batch to limit output\n",
        "        if batch_idx == 0:\n",
        "            break\n",
        "\n",
        "\n",
        "# Check the train, validation, and test loaders\n",
        "print(\"Verifying Train Loader...\")\n",
        "verify_dataloader(train_loader)\n",
        "\n",
        "print(\"Verifying Validation Loader...\")\n",
        "verify_dataloader(val_loader)\n",
        "\n",
        "print(\"Verifying Test Loader...\")\n",
        "verify_dataloader(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIOiD_pKlZeR"
      },
      "source": [
        "# Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0lpya9WxCg"
      },
      "outputs": [],
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, predict_steps=25):\n",
        "      super(BidirectionalLSTM, self).__init__()\n",
        "      '''\n",
        "      input_size: the number of expected features in the input x\n",
        "      hidden_size: the number of features in the hidden state h\n",
        "      num_layers: number of recurrent layers.\n",
        "      '''\n",
        "      self.bilstm = nn.LSTM(\n",
        "          input_size=input_size,\n",
        "          hidden_size=hidden_size,\n",
        "          num_layers=num_layers,\n",
        "          bidirectional=True,\n",
        "          batch_first=True\n",
        "        )\n",
        "      self.predict_steps = predict_steps\n",
        "      self.fc = nn.Linear(hidden_size * 2, self.predict_steps * input_size)  # Output size matches input for next-point prediction\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "      # Pack the padded sequence\n",
        "      packed_x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "      # Pass through BiLSTM\n",
        "      packed_out, (hidden, cell) = self.bilstm(packed_x)\n",
        "\n",
        "      # Unpack the sequence\n",
        "      out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "\n",
        "      # Fully connected layer for next-point prediction\n",
        "      output = self.fc(out)\n",
        "      batch_size, seq_len, feature_size = output.size()\n",
        "      assert feature_size == self.predict_steps * x.size(2), f\"Mismatch in feature size: expected {self.predict_steps * x.size(2)}, got {feature_size}\"\n",
        "\n",
        "      # Reshape to (batch_size, seq_len, predict_steps, input_size)\n",
        "      output = output.view(batch_size, seq_len, self.predict_steps, -1)\n",
        "\n",
        "      return output, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YFS1_79Io8N",
        "outputId": "a9ee78eb-5906-420d-fa1f-37621525b4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output Shape: torch.Size([256, 49, 25, 5])\n",
            "Hidden Shape: torch.Size([256, 64])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "seq_len = 50\n",
        "input_size = 5\n",
        "predict_steps = 25\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "\n",
        "# Dummy input\n",
        "dummy_input = torch.rand(batch_size, seq_len, input_size).to(device)\n",
        "lengths = torch.randint(low=30, high=seq_len, size=(batch_size,)).to('cpu')\n",
        "\n",
        "# Instantiate the model\n",
        "model = BidirectionalLSTM(input_size, hidden_size, num_layers, predict_steps).to(device)\n",
        "\n",
        "# Forward pass\n",
        "output, hidden = model(dummy_input, lengths)\n",
        "print(\"Output Shape:\", output.shape)  # Expected: (batch_size, seq_len, predict_steps, input_size)\n",
        "print(\"Hidden Shape:\", hidden[0].shape)  # Expected: (num_layers * 2, batch_size, hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy90GW_hleIr"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3ZpL3yUqcu2"
      },
      "outputs": [],
      "source": [
        "# Model Hyperparameters\n",
        "input_size = 5  # [x, y, z, angle, depth]\n",
        "hidden_size = 256\n",
        "num_layers = 4\n",
        "\n",
        "model = BidirectionalLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1, min_lr=1e-6)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BVnUhuc7ehe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "\n",
        "def visualize_blstm_fiber(inputs, targets, outputs, lengths, fiber_idx):\n",
        "    \"\"\"\n",
        "    Visualize the input fiber, target points, and predicted points for one fiber processed by BLSTM.\n",
        "\n",
        "    Args:\n",
        "        inputs (Tensor): Input tensor (batch_size, seq_len, input_size).\n",
        "        targets (Tensor): Target tensor (batch_size, seq_len, predict_steps, input_size).\n",
        "        outputs (Tensor): Model outputs (batch_size, seq_len, predict_steps, input_size).\n",
        "        lengths (Tensor): Lengths of valid sequences in the batch.\n",
        "        fiber_idx (int): Index of the fiber in the batch to visualize.\n",
        "    \"\"\"\n",
        "    # Unpack the fiber corresponding to the given fiber_idx\n",
        "    seq_len = lengths[fiber_idx].item()\n",
        "    input_fiber = inputs[fiber_idx, :seq_len, :3].cpu().numpy()  # [x, y, z] of input points\n",
        "    target_points = targets[fiber_idx, :seq_len, :, :3].cpu().numpy()  # [x, y, z] of target points\n",
        "    predicted_points = outputs[fiber_idx, :seq_len, :, :3].detach().cpu().numpy()  # [x, y, z] of predicted points\n",
        "\n",
        "    # Last valid input point\n",
        "    last_input_point = input_fiber[-1]  # Last point of the input trajectory\n",
        "\n",
        "    # Target and predicted next 25 points from the last input point\n",
        "    target_next_points = target_points[-1]  # Shape: (predict_steps, 3)\n",
        "    predicted_next_points = predicted_points[-1]  # Shape: (predict_steps, 3)\n",
        "\n",
        "    # Plot the input fiber trajectory and next points\n",
        "    fig = plt.figure(figsize=(10, 7))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Plot the full input trajectory\n",
        "    ax.plot(input_fiber[:, 0], input_fiber[:, 1], input_fiber[:, 2], label=\"Input Fiber Trajectory\", color='blue')\n",
        "\n",
        "    # Plot the target next points\n",
        "    ax.scatter(target_next_points[:, 0], target_next_points[:, 1], target_next_points[:, 2], label=\"Target Next Points\", color='green')\n",
        "\n",
        "    # Plot the predicted next points\n",
        "    ax.scatter(predicted_next_points[:, 0], predicted_next_points[:, 1], predicted_next_points[:, 2], label=\"Predicted Next Points\", color='red')\n",
        "\n",
        "    # Formatting the plot\n",
        "    ax.set_title(\"BLSTM Fiber Visualization: Trajectory and Predictions\")\n",
        "    ax.set_xlabel(\"X-axis\")\n",
        "    ax.set_ylabel(\"Y-axis\")\n",
        "    ax.set_zlabel(\"Z-axis\")\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "def reload_model(load_path, hidden_size, num_layers):\n",
        "  model = BidirectionalLSTM(input_size=5, hidden_size=hidden_size, num_layers=num_layers).to(device)\n",
        "  checkpoint = torch.load(load_path, map_location=device)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  return model, optimizer, start_epoch, loss\n",
        "\n",
        "def save_model(model, current_epoch, optimizer, scheduler, total_loss, val_loss, save_path):\n",
        "  torch.save({\n",
        "      'epoch': current_epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'scheduler_state_dict': scheduler.state_dict(),\n",
        "      'total training loss': total_loss,\n",
        "      'validation loss': val_loss\n",
        "  }, save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sg4G4ncLWj_"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    viz = False\n",
        "    with torch.no_grad():\n",
        "      for inputs, targets, lengths in dataloader:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          lengths, perm_idx = lengths.sort(0, descending=True)\n",
        "          inputs = inputs[perm_idx]\n",
        "          targets = targets[perm_idx]\n",
        "\n",
        "          outputs, _ = model(inputs, lengths)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          if not viz:\n",
        "              visualize_blstm_fiber(inputs, targets, outputs, lengths, fiber_idx=12)\n",
        "              visualize_blstm_fiber(inputs, targets, outputs, lengths, fiber_idx=120)\n",
        "              viz = True\n",
        "\n",
        "          total_val_loss += loss.item()\n",
        "\n",
        "    return total_val_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9eEjAegHldCg"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()\n",
        "num_epochs = 100\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (inputs, targets, lengths) in enumerate(train_loader):  # lengths added to the DataLoader output\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        lengths, perm_idx = lengths.sort(0, descending=True)\n",
        "        inputs = inputs[perm_idx]\n",
        "        targets = targets[perm_idx]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(str(device)):  # Enables mixed precision\n",
        "          outputs, _ = model(inputs, lengths)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/50], Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    val_loss = validate(model, val_loader, criterion)\n",
        "    print(f\"Epoch [{epoch+1}/50], Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\\n\\n\")\n",
        "\n",
        "    if ((epoch+1) % 5 == 0) and ((epoch+1) >= 5):\n",
        "        save_path = f\"/content/BLSTM_25_point_prediction_epoch_{epoch+1}_version_2.pth\"\n",
        "        save_model(model, epoch, optimizer, scheduler, total_loss, val_loss, save_path)\n",
        "\n",
        "        if ((epoch+1) % 10 == 0) or (epoch == num_epochs - 1):\n",
        "            files.download(save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHhcL_meq1ID"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1gOx9Z6qm2l"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/bilstm_fiber_25_points_v2.pth\"\n",
        "\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9X2hsO4IGM3"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}